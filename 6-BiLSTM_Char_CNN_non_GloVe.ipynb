{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "TmvsBOxDdURG"
      },
      "outputs": [],
      "source": [
        "#Importing dependencies for EDA\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# from validation import compute_f1\n",
        "from keras.models import Model\n",
        "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate\n",
        "# from prepro import readfile,createBatches,createMatrices,iterate_minibatches,addCharInformatioin,padding\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.initializers import RandomUniform\n",
        "\n",
        "#Importing the below block to display all outputs \n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Orad0L8hdURU"
      },
      "outputs": [],
      "source": [
        "#Reading the training file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/NLP/ner_datasetreference.csv\", encoding='latin')\n",
        "df = df.fillna(method='ffill')\n",
        "df[\"Sentence #\"] = df[\"Sentence #\"].apply(lambda s: s[9:]).astype(\"int32\")\n",
        "df[\"Word\"] = df[\"Word\"].apply(lambda x: re.sub(r'http\\S+', ' ',x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "XBXBee7udURX"
      },
      "outputs": [],
      "source": [
        "#Creating a dictionary to replace these latin characters \n",
        "replacement_dict = {'ë':'e','ü':'u',\"\\xa0\":' ', 'é':'e', '\\x93':' ','\\x91':' ','\\x97':' ','\\x85':' ','\\x94':' ','ö':'o' ,'°':' ', \n",
        "                   '\\x92':' ','\\x96':' '}\n",
        "\n",
        "def cleanunicode(uncleanstring):\n",
        "    return re.sub(r'[\\xa0|é|ë|ü|\\x93|\\x91|\\x97|\\x85|\\x94|ö|°|\\x92|\\x96]', lambda m: replacement_dict.get(m.group()), uncleanstring)\n",
        "\n",
        "df['Word'] = df['Word'].apply(lambda x : cleanunicode(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EKYuPDhdURZ",
        "outputId": "450a2900-ddaa-4b4c-a990-7e1e4a37da7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words: 35162\n",
            "Number of unique tags : 17\n"
          ]
        }
      ],
      "source": [
        "# Creating a list of all unique words and unique tags\n",
        "all_words = list(set(df[\"Word\"].values))\n",
        "all_tags = list(set(df[\"Tag\"].values))\n",
        "print(\"Number of unique words: {}\".format(len(all_words)))\n",
        "print(\"Number of unique tags : {}\".format(len(all_tags)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4kAGOdddURe",
        "outputId": "15a5329c-e627-474e-c9fa-e92391a33f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'24th': 2, '1991': 3, 'dispenser': 4, 'season': 5, 'lifeline': 6}\n"
          ]
        }
      ],
      "source": [
        "# Creating a dictionary of of unique words and assigning a unique index number similarly to NER tags as well \n",
        "word2Idx = {word: idx + 2 for idx, word in enumerate(all_words)}\n",
        "word2Idx[\"UNKNOWN_WORD\"]=0\n",
        "word2Idx[\"PADDING\"]= 1\n",
        "\n",
        "print(dict(list(word2Idx.items())[0:5])) ## Dislaying 5 samples\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2Word = {v: k for k, v in word2Idx.items()}\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP/idx2Word_nonGlove.json', 'w') as fp:\n",
        "    json.dump(idx2Word, fp)"
      ],
      "metadata": {
        "id": "e59N_QsUgGU8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NRevpubdURi",
        "outputId": "a0cf2bc4-2769-4964-c340-aa88afcecfb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35164"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "len(word2Idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fk4RVCaBdURp"
      },
      "outputs": [],
      "source": [
        "# Word and tag is combined in a list for each sentence another list is consuructed\n",
        "df['combined']= df[['Word','Tag']].values.tolist()\n",
        "df = df.groupby(['Sentence #'])['combined'].agg(lambda x: list(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I6MUMcrdURs",
        "outputId": "70f033ef-cf3d-490f-d778-52f083c0972c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #\n",
              "1    [[Thousands, O], [of, O], [demonstrators, O], ...\n",
              "2    [[Families, O], [of, O], [soldiers, O], [kille...\n",
              "3    [[They, O], [marched, O], [from, O], [the, O],...\n",
              "4    [[Police, O], [put, O], [the, O], [number, O],...\n",
              "5    [[The, O], [protest, O], [comes, O], [on, O], ...\n",
              "Name: combined, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "8aKqZjHPdURw"
      },
      "outputs": [],
      "source": [
        "trainSentences = df.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1obAAvvdUR0",
        "outputId": "a5349b0c-14b1-4757-bd73-79867722f1b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47959"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(trainSentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "htfaLGF3dUR3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(trainSentences, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM8zrUiEdUR6",
        "outputId": "0c9e7c71-e0cf-481e-ecd0-ae868876e52f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38367"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9592"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(X_train)\n",
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVYEvS2udUR7",
        "outputId": "3298ef7e-357e-4c6f-d176-312630b235ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['No', 'O'],\n",
              " ['official', 'O'],\n",
              " ['announcement', 'O'],\n",
              " ['has', 'O'],\n",
              " ['come', 'O'],\n",
              " ['from', 'O'],\n",
              " ['the', 'O'],\n",
              " ['Iraqi', 'B-gpe'],\n",
              " ['Special', 'O'],\n",
              " ['Tribunal', 'O'],\n",
              " ['in', 'O'],\n",
              " ['charge', 'O'],\n",
              " ['of', 'O'],\n",
              " ['the', 'O'],\n",
              " ['trials', 'O'],\n",
              " [',', 'O'],\n",
              " ['but', 'O'],\n",
              " ['officials', 'O'],\n",
              " ['close', 'O'],\n",
              " ['to', 'O'],\n",
              " ['the', 'O'],\n",
              " ['case', 'O'],\n",
              " ['said', 'O'],\n",
              " ['Friday', 'B-tim'],\n",
              " ['that', 'O'],\n",
              " ['Saddam', 'B-per'],\n",
              " ['Hussein', 'I-per'],\n",
              " ['will', 'O'],\n",
              " ['be', 'O'],\n",
              " ['tried', 'O'],\n",
              " ['for', 'O'],\n",
              " ['the', 'O'],\n",
              " ['1982', 'B-tim'],\n",
              " ['killing', 'O'],\n",
              " ['of', 'O'],\n",
              " ['dozens', 'O'],\n",
              " ['of', 'O'],\n",
              " ['residents', 'O'],\n",
              " ['of', 'O'],\n",
              " ['the', 'O'],\n",
              " ['town', 'O'],\n",
              " ['of', 'O'],\n",
              " ['Dujail', 'B-geo'],\n",
              " ['.', 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yhKNRQradUR_"
      },
      "outputs": [],
      "source": [
        "#This function creates a list of characters in a word\n",
        "def characterSplit(Sentences):\n",
        "    for i,sentence in enumerate(Sentences):\n",
        "        for j,data in enumerate(sentence):\n",
        "            chars = [c for c in data[0]]\n",
        "            Sentences[i][j] = [data[0],chars,data[1]]\n",
        "    return Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vmn81jyddUSB"
      },
      "outputs": [],
      "source": [
        "X_train = characterSplit(X_train)\n",
        "X_test = characterSplit(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_NHH2CdUSF",
        "outputId": "d1d8ad35-ccc8-4b5d-8f41-427f2ba724a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['No', ['N', 'o'], 'O'],\n",
              " ['official', ['o', 'f', 'f', 'i', 'c', 'i', 'a', 'l'], 'O'],\n",
              " ['announcement',\n",
              "  ['a', 'n', 'n', 'o', 'u', 'n', 'c', 'e', 'm', 'e', 'n', 't'],\n",
              "  'O'],\n",
              " ['has', ['h', 'a', 's'], 'O'],\n",
              " ['come', ['c', 'o', 'm', 'e'], 'O'],\n",
              " ['from', ['f', 'r', 'o', 'm'], 'O'],\n",
              " ['the', ['t', 'h', 'e'], 'O'],\n",
              " ['Iraqi', ['I', 'r', 'a', 'q', 'i'], 'B-gpe'],\n",
              " ['Special', ['S', 'p', 'e', 'c', 'i', 'a', 'l'], 'O'],\n",
              " ['Tribunal', ['T', 'r', 'i', 'b', 'u', 'n', 'a', 'l'], 'O'],\n",
              " ['in', ['i', 'n'], 'O'],\n",
              " ['charge', ['c', 'h', 'a', 'r', 'g', 'e'], 'O'],\n",
              " ['of', ['o', 'f'], 'O'],\n",
              " ['the', ['t', 'h', 'e'], 'O'],\n",
              " ['trials', ['t', 'r', 'i', 'a', 'l', 's'], 'O'],\n",
              " [',', [','], 'O'],\n",
              " ['but', ['b', 'u', 't'], 'O'],\n",
              " ['officials', ['o', 'f', 'f', 'i', 'c', 'i', 'a', 'l', 's'], 'O'],\n",
              " ['close', ['c', 'l', 'o', 's', 'e'], 'O'],\n",
              " ['to', ['t', 'o'], 'O'],\n",
              " ['the', ['t', 'h', 'e'], 'O'],\n",
              " ['case', ['c', 'a', 's', 'e'], 'O'],\n",
              " ['said', ['s', 'a', 'i', 'd'], 'O'],\n",
              " ['Friday', ['F', 'r', 'i', 'd', 'a', 'y'], 'B-tim'],\n",
              " ['that', ['t', 'h', 'a', 't'], 'O'],\n",
              " ['Saddam', ['S', 'a', 'd', 'd', 'a', 'm'], 'B-per'],\n",
              " ['Hussein', ['H', 'u', 's', 's', 'e', 'i', 'n'], 'I-per'],\n",
              " ['will', ['w', 'i', 'l', 'l'], 'O'],\n",
              " ['be', ['b', 'e'], 'O'],\n",
              " ['tried', ['t', 'r', 'i', 'e', 'd'], 'O'],\n",
              " ['for', ['f', 'o', 'r'], 'O'],\n",
              " ['the', ['t', 'h', 'e'], 'O'],\n",
              " ['1982', ['1', '9', '8', '2'], 'B-tim'],\n",
              " ['killing', ['k', 'i', 'l', 'l', 'i', 'n', 'g'], 'O'],\n",
              " ['of', ['o', 'f'], 'O'],\n",
              " ['dozens', ['d', 'o', 'z', 'e', 'n', 's'], 'O'],\n",
              " ['of', ['o', 'f'], 'O'],\n",
              " ['residents', ['r', 'e', 's', 'i', 'd', 'e', 'n', 't', 's'], 'O'],\n",
              " ['of', ['o', 'f'], 'O'],\n",
              " ['the', ['t', 'h', 'e'], 'O'],\n",
              " ['town', ['t', 'o', 'w', 'n'], 'O'],\n",
              " ['of', ['o', 'f'], 'O'],\n",
              " ['Dujail', ['D', 'u', 'j', 'a', 'i', 'l'], 'B-geo'],\n",
              " ['.', ['.'], 'O']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hZYG5Vz6dUSH"
      },
      "outputs": [],
      "source": [
        "#This loops create a set of unique tags and a dictionary of unique words\n",
        "labelSet = set()\n",
        "words = {}\n",
        "\n",
        "for dataset in [X_train, X_test]:\n",
        "    for sentence in dataset:\n",
        "        for token,char,label in sentence:\n",
        "            labelSet.add(label)\n",
        "            words[token.lower()] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL4vsS8OdUSI",
        "outputId": "151f95ce-a604-4abe-9456-436eafbdd333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31801"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(labelSet)\n",
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HYZP9wbDdUSL"
      },
      "outputs": [],
      "source": [
        "# :: Create a mapping for the labels ::\n",
        "label2Idx = {}\n",
        "for label in labelSet:\n",
        "    label2Idx[label] = len(label2Idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2Label = {v: k for k, v in label2Idx.items()}\n",
        "\n",
        "with open('/content/drive/MyDrive/NLP/idx2Label_nonGlove.json', 'w') as fp:\n",
        "    json.dump(idx2Label, fp)"
      ],
      "metadata": {
        "id": "uSXxtaHDexOY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qRYQRYZIdUSO"
      },
      "outputs": [],
      "source": [
        "# :: Hard coded case lookup ::\n",
        "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
        "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKwkgpTjdUSP",
        "outputId": "3050fccc-e3d0-46cf-de16-42ebb59cdfca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'PADDING_TOKEN': 7,\n",
              " 'allLower': 1,\n",
              " 'allUpper': 2,\n",
              " 'contains_digit': 6,\n",
              " 'initialUpper': 3,\n",
              " 'mainly_numeric': 5,\n",
              " 'numeric': 0,\n",
              " 'other': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "case2Idx\n",
        "caseEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erkvWI54dUSY",
        "outputId": "078a3b83-fa87-4d91-e05b-3261a7dbdb58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 2,\n",
              " '!': 75,\n",
              " '\"': 81,\n",
              " '#': 79,\n",
              " '$': 85,\n",
              " '%': 84,\n",
              " '&': 87,\n",
              " \"'\": 80,\n",
              " '(': 69,\n",
              " ')': 70,\n",
              " '*': 89,\n",
              " '+': 90,\n",
              " ',': 66,\n",
              " '-': 67,\n",
              " '.': 65,\n",
              " '/': 82,\n",
              " '0': 3,\n",
              " '1': 4,\n",
              " '2': 5,\n",
              " '3': 6,\n",
              " '4': 7,\n",
              " '5': 8,\n",
              " '6': 9,\n",
              " '7': 10,\n",
              " '8': 11,\n",
              " '9': 12,\n",
              " ':': 77,\n",
              " ';': 78,\n",
              " '=': 88,\n",
              " '?': 76,\n",
              " '@': 91,\n",
              " 'A': 39,\n",
              " 'B': 40,\n",
              " 'C': 41,\n",
              " 'D': 42,\n",
              " 'E': 43,\n",
              " 'F': 44,\n",
              " 'G': 45,\n",
              " 'H': 46,\n",
              " 'I': 47,\n",
              " 'J': 48,\n",
              " 'K': 49,\n",
              " 'L': 50,\n",
              " 'M': 51,\n",
              " 'N': 52,\n",
              " 'O': 53,\n",
              " 'P': 54,\n",
              " 'PADDING': 0,\n",
              " 'Q': 55,\n",
              " 'R': 56,\n",
              " 'S': 57,\n",
              " 'T': 58,\n",
              " 'U': 59,\n",
              " 'UNKNOWN': 1,\n",
              " 'V': 60,\n",
              " 'W': 61,\n",
              " 'X': 62,\n",
              " 'Y': 63,\n",
              " 'Z': 64,\n",
              " '[': 71,\n",
              " '\\\\': 83,\n",
              " ']': 72,\n",
              " '^': 92,\n",
              " '_': 68,\n",
              " '`': 86,\n",
              " 'a': 13,\n",
              " 'b': 14,\n",
              " 'c': 15,\n",
              " 'd': 16,\n",
              " 'e': 17,\n",
              " 'f': 18,\n",
              " 'g': 19,\n",
              " 'h': 20,\n",
              " 'i': 21,\n",
              " 'j': 22,\n",
              " 'k': 23,\n",
              " 'l': 24,\n",
              " 'm': 25,\n",
              " 'n': 26,\n",
              " 'o': 27,\n",
              " 'p': 28,\n",
              " 'q': 29,\n",
              " 'r': 30,\n",
              " 's': 31,\n",
              " 't': 32,\n",
              " 'u': 33,\n",
              " 'v': 34,\n",
              " 'w': 35,\n",
              " 'x': 36,\n",
              " 'y': 37,\n",
              " 'z': 38,\n",
              " '{': 73,\n",
              " '|': 94,\n",
              " '}': 74,\n",
              " '~': 93}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#simarlrly creating a character index dictionary of all possible english characters\n",
        "char2Idx = {\"PADDING\":0, \"UNKNOWN\":1}\n",
        "for c in \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|\":\n",
        "    char2Idx[c] = len(char2Idx)\n",
        "len(char2Idx)\n",
        "char2Idx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/NLP/char2Idx_nonGlove.json', 'w') as fp:\n",
        "    json.dump(char2Idx, fp)"
      ],
      "metadata": {
        "id": "nTq9YHydfXw3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QGFgWT2IdUSa"
      },
      "outputs": [],
      "source": [
        "def getCasing(word, caseLookup):   \n",
        "    casing = 'other'\n",
        "    \n",
        "    numDigits = 0\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            numDigits += 1\n",
        "            \n",
        "    digitFraction = numDigits / float(len(word))\n",
        "    \n",
        "    if word.isdigit(): #Is a digit\n",
        "        casing = 'numeric'\n",
        "    elif digitFraction > 0.5:\n",
        "        casing = 'mainly_numeric'\n",
        "    elif word.islower(): #All lower case\n",
        "        casing = 'allLower'\n",
        "    elif word.isupper(): #All upper case\n",
        "        casing = 'allUpper'\n",
        "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
        "        casing = 'initialUpper'\n",
        "    elif numDigits > 0:\n",
        "        casing = 'contains_digit'\n",
        "    \n",
        "   \n",
        "    return caseLookup[casing]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "n7bTUYN3dUSc"
      },
      "outputs": [],
      "source": [
        "def createMatrices(document, word2Idx, label2Idx, case2Idx,char2Idx):\n",
        "    unknownIdx = word2Idx['UNKNOWN_WORD']\n",
        "    paddingIdx = word2Idx['PADDING']    \n",
        "        \n",
        "    dataset = []\n",
        "    \n",
        "    wordCount = 0\n",
        "    unknownWordCount = 0\n",
        "    \n",
        "    for document in document:\n",
        "        wordIndices = []    \n",
        "        caseIndices = []\n",
        "        charIndices = []\n",
        "        labelIndices = []\n",
        "        \n",
        "        for word,char,label in document:  \n",
        "            wordCount += 1\n",
        "            if word in word2Idx:\n",
        "                wordIdx = word2Idx[word]\n",
        "            elif word.lower() in word2Idx:\n",
        "                wordIdx = word2Idx[word.lower()]                 \n",
        "            else:\n",
        "                wordIdx = unknownIdx\n",
        "                unknownWordCount += 1\n",
        "            charIdx = []\n",
        "            for x in char:\n",
        "                charIdx.append(char2Idx[x])\n",
        "            #Get the label and map to int            \n",
        "            wordIndices.append(wordIdx)\n",
        "            caseIndices.append(getCasing(word, case2Idx))\n",
        "            charIndices.append(charIdx)\n",
        "            labelIndices.append(label2Idx[label])\n",
        "           \n",
        "        dataset.append([wordIndices, caseIndices, charIndices, labelIndices]) \n",
        "        \n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kcYqmsIWdUSg",
        "outputId": "2a836ff1-bf6b-4dc8-c886-9eb5a22945d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cricketer-turned-politician'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "key_lenth = [len(i) for i,k in word2Idx.items()]\n",
        "keys = {len(i):i for i,k in word2Idx.items()}\n",
        "keys[max(key_lenth)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SX9DClZCdUSj"
      },
      "outputs": [],
      "source": [
        "#Padding the characters to length of 28\n",
        "def padding(document):\n",
        "    maxlen = 28\n",
        "    for sentence in document:\n",
        "        char = sentence[2]\n",
        "        for x in char:\n",
        "            maxlen = max(maxlen,len(x))\n",
        "    for i,sentence in enumerate(document):\n",
        "        document[i][2] = pad_sequences(document[i][2],28,padding='post')\n",
        "    return document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "o1CtSp0JdUSl"
      },
      "outputs": [],
      "source": [
        "#Above three functions are called on the train and test data\n",
        "train_set = padding(createMatrices(X_train,word2Idx,  label2Idx, case2Idx,char2Idx))\n",
        "test_set = padding(createMatrices(X_test, word2Idx, label2Idx, case2Idx,char2Idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mx0_jRtDdUSp"
      },
      "outputs": [],
      "source": [
        "#This function O/P the dataset and also o/p a list which contain the no of batches which has the same length words in i/p\n",
        "def createBatches(data):\n",
        "    l = []\n",
        "    for i in data:\n",
        "        l.append(len(i[0]))\n",
        "    l = set(l)\n",
        "    batches = []\n",
        "    batch_len = []\n",
        "    z = 0\n",
        "    for i in l:\n",
        "        for batch in data:\n",
        "            if len(batch[0]) == i:\n",
        "                batches.append(batch)\n",
        "                z += 1\n",
        "        batch_len.append(z)\n",
        "    return batches,batch_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5vXp28QadUSq"
      },
      "outputs": [],
      "source": [
        "train_batch,train_batch_len = createBatches(train_set)\n",
        "test_batch,test_batch_len = createBatches(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrmyJG95dUSq",
        "outputId": "b325beac-a161-4bb5-be98-99a887584930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38367"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "len(train_set)\n",
        "len(train_batch_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr-44L40hnGQ",
        "outputId": "6f3489a6-0c79-4c24-ca8b-8e246101203b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32011,\n",
              "  271,\n",
              "  17732,\n",
              "  6843,\n",
              "  26720,\n",
              "  12370,\n",
              "  2107,\n",
              "  29641,\n",
              "  24636,\n",
              "  14498,\n",
              "  9609,\n",
              "  8485,\n",
              "  9758,\n",
              "  2107,\n",
              "  17562,\n",
              "  13941,\n",
              "  25034,\n",
              "  22211,\n",
              "  2847,\n",
              "  34825,\n",
              "  2107,\n",
              "  11216,\n",
              "  14902,\n",
              "  15740,\n",
              "  12767,\n",
              "  26022,\n",
              "  3298,\n",
              "  12034,\n",
              "  32325,\n",
              "  11392,\n",
              "  20627,\n",
              "  2107,\n",
              "  8089,\n",
              "  14727,\n",
              "  9758,\n",
              "  31615,\n",
              "  9758,\n",
              "  12005,\n",
              "  9758,\n",
              "  2107,\n",
              "  1172,\n",
              "  9758,\n",
              "  31857,\n",
              "  9827],\n",
              " [3,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  3,\n",
              "  4],\n",
              " array([[52, 27,  0, ...,  0,  0,  0],\n",
              "        [27, 18, 18, ...,  0,  0,  0],\n",
              "        [13, 26, 26, ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [27, 18,  0, ...,  0,  0,  0],\n",
              "        [42, 33, 22, ...,  0,  0,  0],\n",
              "        [65,  0,  0, ...,  0,  0,  0]], dtype=int32),\n",
              " [7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  0,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  6,\n",
              "  7,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  6,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  8,\n",
              "  7]]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "hT3gImLQdUSu"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(dataset,batch_len): \n",
        "    start = 0\n",
        "    for i in batch_len:\n",
        "        tokens = []\n",
        "        caseing = []\n",
        "        char = []\n",
        "        labels = []\n",
        "        data = dataset[start:i]\n",
        "        start = i\n",
        "        for dt in data:\n",
        "            t,c,ch,l = dt\n",
        "            l = np.expand_dims(l,-1)\n",
        "            tokens.append(t)\n",
        "            caseing.append(c)\n",
        "            char.append(ch)\n",
        "            labels.append(l)\n",
        "        yield np.asarray(labels),np.asarray(tokens),np.asarray(caseing),np.asarray(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gwkgxBtWdUSv"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters used base on the paper minor changes as \n",
        "# the dataset i used to train is very small compared to the dataset they used for training\n",
        "\n",
        "# EPOCHS = 50               # paper: 80\n",
        "# DROPOUT = 0.5             # paper: 0.68\n",
        "# DROPOUT_RECURRENT = 0.25  # not specified in paper, 0.25 recommended\n",
        "# LSTM_STATE_SIZE = 200     # paper: 275\n",
        "# CONV_SIZE = 3             # paper: 3\n",
        "# LEARNING_RATE = 0.0105    # paper 0.0105\n",
        "# OPTIMIZER = Nadam()       # paper uses SGD(lr=self.learning_rate), Nadam() recommended for smaller dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FuOW1RwdUSx",
        "outputId": "7226f2ed-f441-4695-e455-050f42f399ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, None, 28)]   0           []                               \n",
            "                                                                                                  \n",
            " char_embedding (TimeDistribute  (None, None, 28, 30  2850       ['char_input[0][0]']             \n",
            " d)                             )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, None, 28, 30  0           ['char_embedding[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 28, 30  2730       ['dropout[0][0]']                \n",
            " ted)                           )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, None, 1, 30)  0          ['time_distributed[0][0]']       \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " words_input (InputLayer)       [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " casing_input (InputLayer)      [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, None, 30)    0           ['time_distributed_1[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 20)     703280      ['words_input[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 8)      64          ['casing_input[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 30)     0           ['time_distributed_2[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, 58)     0           ['embedding[0][0]',              \n",
            "                                                                  'embedding_1[0][0]',            \n",
            "                                                                  'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, None, 400)    414400      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, None, 17)    6817        ['bidirectional[0][0]']          \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,130,141\n",
            "Trainable params: 1,130,077\n",
            "Non-trainable params: 64\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Word Embedding\n",
        "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "words = Embedding(input_dim=len(word2Idx), output_dim=20)(words_input) #,  weights=[wordEmbeddings], trainable=False\n",
        "\n",
        "#Case embedding of each words\n",
        "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
        "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
        "\n",
        "#Character embedding using 1D CNN\n",
        "character_input=Input(shape=(None,28,),name='char_input')\n",
        "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
        "dropout= Dropout(0.5)(embed_char_out)\n",
        "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout)\n",
        "maxpool_out=TimeDistributed(MaxPooling1D(28))(conv1d_out)\n",
        "char = TimeDistributed(Flatten())(maxpool_out)\n",
        "char = Dropout(0.5)(char)\n",
        "\n",
        "#Concatnating the embedded layer o/p together\n",
        "output = concatenate([words, casing, char])\n",
        "output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
        "output = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output)\n",
        "\n",
        "model = Model(inputs=[words_input, casing_input, character_input], outputs=[output])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv4S8-lNdUS0",
        "outputId": "ec92d992-2b3e-4399-a70c-1ecf79f05046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50\n",
            "71/71 [==============================] - 93s 1s/step\n",
            " \n",
            "Epoch 1/50\n",
            "71/71 [==============================] - 87s 1s/step\n",
            " \n",
            "Epoch 2/50\n",
            "71/71 [==============================] - 88s 1s/step\n",
            " \n",
            "Epoch 3/50\n",
            "71/71 [==============================] - 86s 1s/step\n",
            " \n",
            "Epoch 4/50\n",
            "71/71 [==============================] - 86s 1s/step\n",
            " \n",
            "Epoch 5/50\n",
            "71/71 [==============================] - 88s 1s/step\n",
            " \n",
            "Epoch 6/50\n",
            "71/71 [==============================] - 98s 1s/step\n",
            " \n",
            "Epoch 7/50\n",
            "71/71 [==============================] - 87s 1s/step\n",
            " \n",
            "Epoch 8/50\n",
            "71/71 [==============================] - 105s 1s/step\n",
            " \n",
            "Epoch 9/50\n",
            "71/71 [==============================] - 91s 1s/step\n",
            " \n",
            "Epoch 10/50\n",
            "71/71 [==============================] - 106s 1s/step\n",
            " \n",
            "Epoch 11/50\n",
            "71/71 [==============================] - 98s 1s/step\n",
            " \n",
            "Epoch 12/50\n",
            "71/71 [==============================] - 104s 1s/step\n",
            " \n",
            "Epoch 13/50\n",
            "71/71 [==============================] - 106s 1s/step\n",
            " \n",
            "Epoch 14/50\n",
            "71/71 [==============================] - 111s 2s/step\n",
            " \n",
            "Epoch 15/50\n",
            "71/71 [==============================] - 123s 2s/step\n",
            " \n",
            "Epoch 16/50\n",
            "71/71 [==============================] - 120s 2s/step\n",
            " \n",
            "Epoch 17/50\n",
            "71/71 [==============================] - 111s 2s/step\n",
            " \n",
            "Epoch 18/50\n",
            "71/71 [==============================] - 96s 1s/step\n",
            " \n",
            "Epoch 19/50\n",
            "71/71 [==============================] - 113s 2s/step\n",
            " \n",
            "Epoch 20/50\n",
            "71/71 [==============================] - 123s 2s/step\n",
            " \n",
            "Epoch 21/50\n",
            "71/71 [==============================] - 126s 2s/step\n",
            " \n",
            "Epoch 22/50\n",
            "71/71 [==============================] - 126s 2s/step\n",
            " \n",
            "Epoch 23/50\n",
            "71/71 [==============================] - 114s 2s/step\n",
            " \n",
            "Epoch 24/50\n",
            "71/71 [==============================] - 117s 2s/step\n",
            " \n",
            "Epoch 25/50\n",
            "71/71 [==============================] - 121s 2s/step\n",
            " \n",
            "Epoch 26/50\n",
            "71/71 [==============================] - 94s 1s/step\n",
            " \n",
            "Epoch 27/50\n",
            "71/71 [==============================] - 125s 2s/step\n",
            " \n",
            "Epoch 28/50\n",
            "71/71 [==============================] - 130s 2s/step\n",
            " \n",
            "Epoch 29/50\n",
            "71/71 [==============================] - 126s 2s/step\n",
            " \n",
            "Epoch 30/50\n",
            "71/71 [==============================] - 122s 2s/step\n",
            " \n",
            "Epoch 31/50\n",
            "71/71 [==============================] - 122s 2s/step\n",
            " \n",
            "Epoch 32/50\n",
            "71/71 [==============================] - 130s 2s/step\n",
            " \n",
            "Epoch 33/50\n",
            "71/71 [==============================] - 121s 2s/step\n",
            " \n",
            "Epoch 34/50\n",
            "71/71 [==============================] - 118s 2s/step\n",
            " \n",
            "Epoch 35/50\n",
            "71/71 [==============================] - 95s 1s/step\n",
            " \n",
            "Epoch 36/50\n",
            "71/71 [==============================] - 97s 1s/step\n",
            " \n",
            "Epoch 37/50\n",
            "71/71 [==============================] - 93s 1s/step\n",
            " \n",
            "Epoch 38/50\n",
            "71/71 [==============================] - 95s 1s/step\n",
            " \n",
            "Epoch 39/50\n",
            "71/71 [==============================] - 95s 1s/step\n",
            " \n",
            "Epoch 40/50\n",
            "71/71 [==============================] - 90s 1s/step\n",
            " \n",
            "Epoch 41/50\n",
            "71/71 [==============================] - 95s 1s/step\n",
            " \n",
            "Epoch 42/50\n",
            "71/71 [==============================] - 94s 1s/step\n",
            " \n",
            "Epoch 43/50\n",
            "71/71 [==============================] - 92s 1s/step\n",
            " \n",
            "Epoch 44/50\n",
            "71/71 [==============================] - 95s 1s/step\n",
            " \n",
            "Epoch 45/50\n",
            "71/71 [==============================] - 94s 1s/step\n",
            " \n",
            "Epoch 46/50\n",
            "71/71 [==============================] - 90s 1s/step\n",
            " \n",
            "Epoch 47/50\n",
            "71/71 [==============================] - 96s 1s/step\n",
            " \n",
            "Epoch 48/50\n",
            "71/71 [==============================] - 95s 1s/step\n",
            " \n",
            "Epoch 49/50\n",
            "71/71 [==============================] - 94s 1s/step\n",
            " \n",
            "CPU times: user 2h 5min 48s, sys: 24min 55s, total: 2h 30min 43s\n",
            "Wall time: 1h 27min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#Training the model on batches\n",
        "epochs = 50\n",
        "for epoch in range(epochs):    \n",
        "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
        "    a = Progbar(len(train_batch_len))\n",
        "    for i,batch in enumerate(iterate_minibatches(train_batch,train_batch_len)):\n",
        "        labels, tokens, casing,char = batch       \n",
        "        history = model.train_on_batch([tokens, casing, char], labels,return_dict=True,reset_metrics=False)\n",
        "        a.update(i)\n",
        "    a.update(i+1)\n",
        "    print(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7gYRh8NdUS3",
        "outputId": "b8b24f93-1260-4d2a-ef9b-99882ea8bd60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.1432882696390152}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUx0iynCdUS5"
      },
      "outputs": [],
      "source": [
        "model.save(\"BiLSTM_CNN_nonGolVe/model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5qc3AUSidUS5"
      },
      "outputs": [],
      "source": [
        "def predict_dataset(dataset):\n",
        "    sentences = []\n",
        "    correctLabels = []\n",
        "    predLabels = []\n",
        "    b = Progbar(len(dataset))\n",
        "    for i,data in enumerate(dataset):    \n",
        "        tokens, casing,char, labels = data\n",
        "        sentences.append(tokens)\n",
        "        tokens = np.asarray([tokens])     \n",
        "        casing = np.asarray([casing])\n",
        "        char = np.asarray([char])\n",
        "        pred = model.predict([tokens, casing,char], verbose=False)[0]   \n",
        "        pred = pred.argmax(axis=-1) #Predict the classes \n",
        "        correctLabels.append(labels)\n",
        "        predLabels.append(pred)\n",
        "        b.update(i)\n",
        "    b.update(i+1)\n",
        "    return predLabels, correctLabels, sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLSHkX0AdUS6",
        "outputId": "4be51f56-9a3f-48d0-9f83-3f4be54929e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9592/9592 [==============================] - 594s 62ms/step\n"
          ]
        }
      ],
      "source": [
        "predLabels, correctLabels, sentences = predict_dataset(test_batch) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "r5zz3iGtdUS7"
      },
      "outputs": [],
      "source": [
        "#Returns the labels of index\n",
        "def pred2label(pred,diction):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(str(diction[p]))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "pred_labels = pred2label(predLabels,idx2Label)\n",
        "true_labels = pred2label(correctLabels,idx2Label)\n",
        "actual_words = pred2label(sentences,idx2Word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fArrReaBdUS8",
        "outputId": "19343d53-26b8-4c48-f954-0f0891de07a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 79.3%\n",
            "precision_score: 79.5%\n",
            "recall_score: 79.1%\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(true_labels, pred_labels)))\n",
        "print(\"precision_score: {:.1%}\".format(precision_score(true_labels, pred_labels)))\n",
        "print(\"recall_score: {:.1%}\".format(recall_score(true_labels, pred_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a flat list to look at Classification report\n",
        "test_pred = [ j for i in pred_labels for j in i]\n",
        "true_lab = [ j for i in true_labels for j in i]"
      ],
      "metadata": {
        "id": "Lt9eHYxifiDd"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_pred, true_lab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCEBfCQWfmzx",
        "outputId": "3f768273-c21c-42a5-c2a7-6e17fdecab24"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00         5\n",
            "       B-eve       0.15      0.60      0.24        15\n",
            "       B-geo       0.90      0.83      0.86      8162\n",
            "       B-gpe       0.93      0.95      0.94      3143\n",
            "       B-nat       0.00      0.00      0.00         1\n",
            "       B-org       0.65      0.79      0.72      3279\n",
            "       B-per       0.76      0.85      0.81      3009\n",
            "       B-tim       0.88      0.90      0.89      3957\n",
            "       I-art       0.00      0.00      0.00        10\n",
            "       I-eve       0.02      0.33      0.04         3\n",
            "       I-geo       0.79      0.77      0.78      1533\n",
            "       I-gpe       0.43      0.90      0.58        21\n",
            "       I-nat       0.00      0.00      0.00         0\n",
            "       I-org       0.68      0.82      0.74      2715\n",
            "       I-per       0.76      0.89      0.82      2914\n",
            "       I-tim       0.71      0.81      0.76      1181\n",
            "           O       0.99      0.98      0.99    180127\n",
            "\n",
            "    accuracy                           0.96    210075\n",
            "   macro avg       0.51      0.61      0.54    210075\n",
            "weighted avg       0.97      0.96      0.97    210075\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK5hJJJ8dUS9",
        "outputId": "abe7f3ac-a248-404c-ff98-a827e73fc61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word           True \tPred\n",
            "\n",
            "------------------------------\n",
            "Austrian       B-gpe\tB-gpe\n",
            "officials      O\tO\n",
            "Wednesday      B-tim\tB-tim\n",
            "reported       O\tO\n",
            "the            O\tO\n",
            "first          O\tO\n",
            "European       B-org\tB-org\n",
            "Union          I-org\tI-org\n",
            "case           O\tO\n",
            "of             O\tO\n",
            "the            O\tO\n",
            "deadly         O\tO\n",
            "disease        O\tO\n",
            "in             O\tO\n",
            "poultry        O\tO\n",
            ".              O\tO\n"
          ]
        }
      ],
      "source": [
        "print(\"{:15}{:5}\\t{}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
        "print(\"-\"*30)\n",
        "\n",
        "i = np.random.randint(0, len(actual_words))\n",
        "\n",
        "for (w, t, pred) in zip(actual_words[i], true_labels[i], pred_labels[i]):\n",
        "    print(\"{:15}{}\\t{}\".format(w, t, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JBC8G5V5dUS-"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/NLP/HalfTrainedModels/Half_Trained_model_non_glove.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training on full dataset\n",
        "#Model layers \n",
        "\n",
        "#Word Embedding part\n",
        "words_input_full = Input(shape=(None,),dtype='int32',name='words_input')\n",
        "words_full = Embedding(input_dim=len(word2Idx), output_dim=20)(words_input_full) # weights=[wordEmbeddings], trainable=False)(words_input_full)\n",
        "\n",
        "#Case embedding part of each word\n",
        "casing_input_full = Input(shape=(None,), dtype='int32', name='casing_input')\n",
        "casing_full = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input_full)\n",
        "\n",
        "#Character embedding using 1D CNN\n",
        "character_input_full = Input(shape=(None,28,),name='char_input')\n",
        "embed_char_out_full = TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input_full)\n",
        "dropout_full = Dropout(0.5)(embed_char_out_full)\n",
        "conv1d_out_full = TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout_full)\n",
        "maxpool_out_full =TimeDistributed(MaxPooling1D(28))(conv1d_out_full)\n",
        "char_full = TimeDistributed(Flatten())(maxpool_out_full)\n",
        "char_full = Dropout(0.5)(char_full)\n",
        "\n",
        "#Concatnating the embedded layer o/p together\n",
        "output_full = concatenate([words_full, casing_full, char_full])\n",
        "output_full = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output_full)\n",
        "output_full = TimeDistributed(Dense(len(label2Idx), activation='softmax'))(output_full)\n",
        "\n",
        "#Specifying input and o/p of the model\n",
        "Full_Trained_model_non_glove = Model(inputs=[words_input_full, casing_input_full, character_input_full], outputs=[output_full])\n",
        "\n",
        "#Compliling the model and looking at model summary\n",
        "Full_Trained_model_non_glove.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
        "Full_Trained_model_non_glove.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUPH3jqkAlev",
        "outputId": "5ab8e052-a91f-4abd-f3ab-dd4d47e3f7f3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, None, 28)]   0           []                               \n",
            "                                                                                                  \n",
            " char_embedding (TimeDistribute  (None, None, 28, 30  2850       ['char_input[0][0]']             \n",
            " d)                             )                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, None, 28, 30  0           ['char_embedding[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_8 (TimeDistri  (None, None, 28, 30  2730       ['dropout_4[0][0]']              \n",
            " buted)                         )                                                                 \n",
            "                                                                                                  \n",
            " time_distributed_9 (TimeDistri  (None, None, 1, 30)  0          ['time_distributed_8[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " words_input (InputLayer)       [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " casing_input (InputLayer)      [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " time_distributed_10 (TimeDistr  (None, None, 30)    0           ['time_distributed_9[0][0]']     \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)        (None, None, 20)     703280      ['words_input[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, None, 8)      64          ['casing_input[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, None, 30)     0           ['time_distributed_10[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, None, 58)     0           ['embedding_6[0][0]',            \n",
            "                                                                  'embedding_7[0][0]',            \n",
            "                                                                  'dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, None, 400)   414400      ['concatenate_2[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_11 (TimeDistr  (None, None, 17)    6817        ['bidirectional_2[0][0]']        \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,130,141\n",
            "Trainable params: 1,130,077\n",
            "Non-trainable params: 64\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainSentences = characterSplit(trainSentences)\n",
        "full_train_data = padding(createMatrices(trainSentences ,word2Idx,  label2Idx, case2Idx, char2Idx))\n",
        "full_train_data_batch,full_train_data_batch_len = createBatches(full_train_data)"
      ],
      "metadata": {
        "id": "WWFUSlvUBirz"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Training the model on full data with batches and for 50 epochs \n",
        "epochs = 50\n",
        "for epoch in range(epochs):    \n",
        "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
        "    a = Progbar(len(full_train_data_batch_len))\n",
        "    for i,batch in enumerate(iterate_minibatches(full_train_data_batch,full_train_data_batch_len)):\n",
        "        labels, tokens, casing, char = batch       \n",
        "        Full_Trained_model_non_glove.train_on_batch([tokens, casing, char], labels)\n",
        "        a.update(i)\n",
        "    a.update(i+1)\n",
        "    print(' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMy41taHDKK2",
        "outputId": "3ae741eb-9123-4939-c686-74d575a6ca0e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50\n",
            "71/71 [==============================] - 115s 2s/step\n",
            " \n",
            "Epoch 1/50\n",
            "71/71 [==============================] - 106s 1s/step\n",
            " \n",
            "Epoch 2/50\n",
            "71/71 [==============================] - 111s 2s/step\n",
            " \n",
            "Epoch 3/50\n",
            "71/71 [==============================] - 107s 2s/step\n",
            " \n",
            "Epoch 4/50\n",
            "71/71 [==============================] - 110s 2s/step\n",
            " \n",
            "Epoch 5/50\n",
            "71/71 [==============================] - 125s 2s/step\n",
            " \n",
            "Epoch 6/50\n",
            "71/71 [==============================] - 124s 2s/step\n",
            " \n",
            "Epoch 7/50\n",
            "71/71 [==============================] - 121s 2s/step\n",
            " \n",
            "Epoch 8/50\n",
            "71/71 [==============================] - 119s 2s/step\n",
            " \n",
            "Epoch 9/50\n",
            "71/71 [==============================] - 123s 2s/step\n",
            " \n",
            "Epoch 10/50\n",
            "71/71 [==============================] - 123s 2s/step\n",
            " \n",
            "Epoch 11/50\n",
            "71/71 [==============================] - 130s 2s/step\n",
            " \n",
            "Epoch 12/50\n",
            "71/71 [==============================] - 128s 2s/step\n",
            " \n",
            "Epoch 13/50\n",
            "71/71 [==============================] - 135s 2s/step\n",
            " \n",
            "Epoch 14/50\n",
            "71/71 [==============================] - 136s 2s/step\n",
            " \n",
            "Epoch 15/50\n",
            "71/71 [==============================] - 138s 2s/step\n",
            " \n",
            "Epoch 16/50\n",
            "71/71 [==============================] - 128s 2s/step\n",
            " \n",
            "Epoch 17/50\n",
            "71/71 [==============================] - 126s 2s/step\n",
            " \n",
            "Epoch 18/50\n",
            "71/71 [==============================] - 131s 2s/step\n",
            " \n",
            "Epoch 19/50\n",
            "71/71 [==============================] - 134s 2s/step\n",
            " \n",
            "Epoch 20/50\n",
            "71/71 [==============================] - 127s 2s/step\n",
            " \n",
            "Epoch 21/50\n",
            "71/71 [==============================] - 142s 2s/step\n",
            " \n",
            "Epoch 22/50\n",
            "71/71 [==============================] - 132s 2s/step\n",
            " \n",
            "Epoch 23/50\n",
            "71/71 [==============================] - 139s 2s/step\n",
            " \n",
            "Epoch 24/50\n",
            "71/71 [==============================] - 135s 2s/step\n",
            " \n",
            "Epoch 25/50\n",
            "71/71 [==============================] - 160s 2s/step\n",
            " \n",
            "Epoch 26/50\n",
            "71/71 [==============================] - 138s 2s/step\n",
            " \n",
            "Epoch 27/50\n",
            "71/71 [==============================] - 137s 2s/step\n",
            " \n",
            "Epoch 28/50\n",
            "71/71 [==============================] - 136s 2s/step\n",
            " \n",
            "Epoch 29/50\n",
            "71/71 [==============================] - 136s 2s/step\n",
            " \n",
            "Epoch 30/50\n",
            "71/71 [==============================] - 125s 2s/step\n",
            " \n",
            "Epoch 31/50\n",
            "71/71 [==============================] - 135s 2s/step\n",
            " \n",
            "Epoch 32/50\n",
            "71/71 [==============================] - 128s 2s/step\n",
            " \n",
            "Epoch 33/50\n",
            "71/71 [==============================] - 127s 2s/step\n",
            " \n",
            "Epoch 34/50\n",
            "71/71 [==============================] - 128s 2s/step\n",
            " \n",
            "Epoch 35/50\n",
            "71/71 [==============================] - 132s 2s/step\n",
            " \n",
            "Epoch 36/50\n",
            "71/71 [==============================] - 136s 2s/step\n",
            " \n",
            "Epoch 37/50\n",
            "71/71 [==============================] - 131s 2s/step\n",
            " \n",
            "Epoch 38/50\n",
            "71/71 [==============================] - 125s 2s/step\n",
            " \n",
            "Epoch 39/50\n",
            "71/71 [==============================] - 128s 2s/step\n",
            " \n",
            "Epoch 40/50\n",
            "71/71 [==============================] - 128s 2s/step\n",
            " \n",
            "Epoch 41/50\n",
            "71/71 [==============================] - 137s 2s/step\n",
            " \n",
            "Epoch 42/50\n",
            "71/71 [==============================] - 148s 2s/step\n",
            " \n",
            "Epoch 43/50\n",
            "71/71 [==============================] - 148s 2s/step\n",
            " \n",
            "Epoch 44/50\n",
            "71/71 [==============================] - 159s 2s/step\n",
            " \n",
            "Epoch 45/50\n",
            "71/71 [==============================] - 152s 2s/step\n",
            " \n",
            "Epoch 46/50\n",
            "71/71 [==============================] - 141s 2s/step\n",
            " \n",
            "Epoch 47/50\n",
            "71/71 [==============================] - 155s 2s/step\n",
            " \n",
            "Epoch 48/50\n",
            "71/71 [==============================] - 158s 2s/step\n",
            " \n",
            "Epoch 49/50\n",
            "71/71 [==============================] - 165s 2s/step\n",
            " \n",
            "CPU times: user 2h 38min 16s, sys: 31min 58s, total: 3h 10min 14s\n",
            "Wall time: 1h 50min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Full_Trained_model_non_glove.save(\"/content/drive/MyDrive/NLP/TrainedModels/Full_Trained_model_non_glove.h5\")"
      ],
      "metadata": {
        "id": "-KTV0P5nQDhW"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "LoadedModel = keras.models.load_model(\"TrainedModels/Full_Trained_model_non_glove.h5\")\n",
        "\n",
        "#Reading the dictionaries back \n",
        "with open('idx2Word_Glove.json', 'r') as fp:\n",
        "    idx2Word = json.load(fp)\n",
        "    \n",
        "with open('idx2Label_Glove.json', 'r') as fp:\n",
        "    idx2Label = json.load(fp)"
      ],
      "metadata": {
        "id": "RjI2rgC5QG09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Readig the cleaned dataset\n",
        "ClimateChange_DF = pd.read_csv(\"/content/drive/MyDrive/NLP_Files/NLP/TaskDataset/Cleaned_English_tweets.csv\")\n",
        "#keeping only the tweets\n",
        "ClimateChange_DF = ClimateChange_DF[[\"CleanedTweets\"]]\n",
        "ClimateChange_DF.head()\n",
        "ClimateChange_DF.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TSKVvjgCQHnC",
        "outputId": "33cf4293-9be8-4f49-bc78-ec8e16b8c6e4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cfaf0507-9f7b-4252-b3b5-06cfc26f37d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanedTweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>News Trends Data Americans are less concerned ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Do you realize that civil war is the devastati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Having anxiety over the weather something they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the last few years I've noticed that studen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIV...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfaf0507-9f7b-4252-b3b5-06cfc26f37d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfaf0507-9f7b-4252-b3b5-06cfc26f37d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfaf0507-9f7b-4252-b3b5-06cfc26f37d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                       CleanedTweets\n",
              "0  News Trends Data Americans are less concerned ...\n",
              "1  Do you realize that civil war is the devastati...\n",
              "2  Having anxiety over the weather something they...\n",
              "3  In the last few years I've noticed that studen...\n",
              "4  FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIV..."
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1557690, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting first 1000 tweets for ease of processing in next steps\n",
        "ClimateChange_DF_Sliced = ClimateChange_DF.iloc[:10000].copy()"
      ],
      "metadata": {
        "id": "Zg5ZXgLwQJIc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ClimateChange_DF_Sliced[\"Word\"] = ClimateChange_DF_Sliced[\"CleanedTweets\"].apply(lambda x: [[i] for i in str(x).split()])\n",
        "ClimateChange_DF_Sliced.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4lm7k-3JQP-o",
        "outputId": "0888c522-8c03-4049-d73f-7d354deb7e0d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a49c35a8-b2ec-45bd-8934-a12d54c2320e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanedTweets</th>\n",
              "      <th>Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>News Trends Data Americans are less concerned ...</td>\n",
              "      <td>[[News], [Trends], [Data], [Americans], [are],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Do you realize that civil war is the devastati...</td>\n",
              "      <td>[[Do], [you], [realize], [that], [civil], [war...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Having anxiety over the weather something they...</td>\n",
              "      <td>[[Having], [anxiety], [over], [the], [weather]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the last few years I've noticed that studen...</td>\n",
              "      <td>[[In], [the], [last], [few], [years], [I've], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIV...</td>\n",
              "      <td>[[FULL], [INTERVIEW], [BTS], [ARMY], [BTSonGMA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a49c35a8-b2ec-45bd-8934-a12d54c2320e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a49c35a8-b2ec-45bd-8934-a12d54c2320e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a49c35a8-b2ec-45bd-8934-a12d54c2320e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                       CleanedTweets                                               Word\n",
              "0  News Trends Data Americans are less concerned ...  [[News], [Trends], [Data], [Americans], [are],...\n",
              "1  Do you realize that civil war is the devastati...  [[Do], [you], [realize], [that], [civil], [war...\n",
              "2  Having anxiety over the weather something they...  [[Having], [anxiety], [over], [the], [weather]...\n",
              "3  In the last few years I've noticed that studen...  [[In], [the], [last], [few], [years], [I've], ...\n",
              "4  FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIV...  [[FULL], [INTERVIEW], [BTS], [ARMY], [BTSonGMA..."
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climate_change = ClimateChange_DF_Sliced.Word.tolist()"
      ],
      "metadata": {
        "id": "nSco_X-BQSk-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splits the word into list of chatracters\n",
        "def FcharacterSplit(Sentences):\n",
        "    for i,sentence in enumerate(Sentences):\n",
        "        for j,data in enumerate(sentence):\n",
        "            chars = [c for c in data[0]]\n",
        "            Sentences[i][j] = [data[0],chars]\n",
        "    return Sentences\n",
        "\n",
        "predicting_sentence = FcharacterSplit(climate_change)"
      ],
      "metadata": {
        "id": "21uO13gTQUQZ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Addiing a dummy tag to process easilly\n",
        "for i in predicting_sentence:\n",
        "    for j in i:\n",
        "        j.append('O')"
      ],
      "metadata": {
        "id": "qJH0tMVHQV97"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "climateChange_pred_data = padding(createMatrices(predicting_sentence, word2Idx, label2Idx, case2Idx,char2Idx))"
      ],
      "metadata": {
        "id": "xW1Ck5WhQWnE"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.random.randint(0, len(climateChange_pred_data))\n",
        "print(i)\n",
        "for j, data in enumerate(climateChange_pred_data[i:i+1]):\n",
        "    tokens, casing, char, labels = data\n",
        "    token = np.asarray([tokens])     \n",
        "    casing = np.asarray([casing])\n",
        "    char = np.asarray([char])\n",
        "    pred = Full_Trained_model_non_glove.predict([token, casing,char], verbose=False)[0]   \n",
        "    pred = pred.argmax(axis=-1) #Predict the classes "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqrM-jZSQYQd",
        "outputId": "6a08bd7c-fe8d-40be-bd6e-264d67494e1a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns the labels of index\n",
        "def pred2label(pred,diction):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out.append(diction[pred_i])\n",
        "    return out\n",
        "\n",
        "pred_labels = pred2label(pred,idx2Label)\n",
        "actual_words = pred2label(tokens,idx2Word)"
      ],
      "metadata": {
        "id": "b3lfDYB0QZmn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:15}{:15}{}\".format(\"Original_Word\", \"Passed_Word\", \"Tag_Predicted\"))\n",
        "print(\"-\"*30)\n",
        "\n",
        "for (o, w, pred) in zip(ClimateChange_DF_Sliced.CleanedTweets[i].split(), actual_words, pred_labels):\n",
        "    print(\"{:15}{:15}{}\".format(o, w, pred))\n",
        "\n",
        "#Using Spacy to cross check for entities\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "text = nlp(ClimateChange_DF_Sliced.CleanedTweets[i])\n",
        "displacy.render(text, style = 'ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "8Zwq6SHyQbRS",
        "outputId": "5e94acd9-ee11-4595-f41f-fa0613ec7ecc"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original_Word  Passed_Word    Tag_Predicted\n",
            "------------------------------\n",
            "The            The            O\n",
            "problem        problem        O\n",
            "with           with           O\n",
            "Australia      Australia      B-geo\n",
            "not            not            O\n",
            "wanting        wanting        O\n",
            "to             to             O\n",
            "be             be             O\n",
            "seen           seen           O\n",
            "as             as             O\n",
            "being          being          O\n",
            "out            out            O\n",
            "of             of             O\n",
            "step           step           O\n",
            "with           with           O\n",
            "likeminded     UNKNOWN_WORD   O\n",
            "democracies    democracies    O\n",
            "on             on             O\n",
            "climate        climate        O\n",
            "change         change         O\n",
            "i              UNKNOWN_WORD   O\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The problem with \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Australia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " not wanting to be seen as being out of step with likeminded democracies on climate change i </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "BiLSTM_Char_CNN_non_GloVe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}