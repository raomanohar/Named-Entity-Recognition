{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook predicts the Named Entities for a selected string from Climate-Change dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Custom library\n",
    "from predifinedfunctions import characterSplit, addDummy, predictedDisplay, predictTags, padding, createMatrices, getCasing\n",
    "# For prediction validation\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing NER Recognition models\n",
    "\n",
    "#BILSTM\n",
    "BiLSTM_Final_model = keras.models.load_model('TrainedModels/BiLSTM_Final_model.h5')\n",
    "with open('word2index.json', 'r') as fp:\n",
    "    word2index_1 = json.load(fp)    \n",
    "with open('tag2index.json', 'r') as fp:\n",
    "    tag2index_1 = json.load(fp)\n",
    "\n",
    "#BILSTM-Strict-Clean\n",
    "BiLSTM_Final_model_strict_clean = keras.models.load_model('TrainedModels/BiLSTM_Final_model_Strict_Clean.h5')\n",
    "with open('word2index_strict_cleaned.json', 'r') as fp:\n",
    "    word2index_2 = json.load(fp)    \n",
    "with open('tag2index_strict_cleaned.json', 'r') as fp:\n",
    "    tag2index_2 = json.load(fp)\n",
    "\n",
    "#Bi-LSTM_CNN_GloVe    \n",
    "BiLSTM_CNN_model_glove = keras.models.load_model('TrainedModels/Full_Trained_model_glove.h5')\n",
    "with open('idx2Word_Glove.json', 'r') as fp:\n",
    "    idx2Word_Glove = json.load(fp)    \n",
    "with open('idx2Label_Glove.json', 'r') as fp:\n",
    "    idx2Label_Glove = json.load(fp)\n",
    "\n",
    "#Bi-LSTM_CNN_nonGloVe  \n",
    "BiLSTM_CNN_model_non_glove = keras.models.load_model('TrainedModels/Full_Trained_model_non_glove.h5')\n",
    "with open('idx2Word_nonGlove.json', 'r') as fp:\n",
    "    idx2Word_nonGlove = json.load(fp)    \n",
    "with open('idx2Label_nonGlove.json', 'r') as fp:\n",
    "    idx2Label_nonGlove = json.load(fp)\n",
    "    \n",
    "#Importing additional dependencies    \n",
    "with open('case2Idx.json', 'r') as fp:\n",
    "    case2Idx = json.load(fp)    \n",
    "with open('char2Idx.json', 'r') as fp:\n",
    "    char2Idx = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Readig the Climate-Change Dataset and selecting top 10k tweets\n",
    "ClimateChange_DF = pd.read_csv(\"Cleaned_English_tweets.csv\")\n",
    "ClimateChange_DF = ClimateChange_DF[[\"CleanedTweets\"]].iloc[:10000].copy()\n",
    "ClimateChange_DF.head()\n",
    "ClimateChange_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of word index with padding for the first two models\n",
    "ClimateChange_DF[\"1Word\"] = ClimateChange_DF[\"CleanedTweets\"].apply(lambda x: str(x).split())\n",
    "ClimateChange_DF[\"2Word\"] = ClimateChange_DF[\"CleanedTweets\"].apply(lambda x: str(x).lower().split())\n",
    "ClimateChange_DF['1Word_Index'] = ClimateChange_DF['1Word'].apply(lambda x: [word2index_1[s] if s in word2index_1 else word2index_1['UNKNOWN_WORD'] for s in x])\n",
    "ClimateChange_DF['2Word_Index'] = ClimateChange_DF['2Word'].apply(lambda x: [word2index_2[s] if s in word2index_2 else word2index_2['UNKNOWN_WORD'] for s in x])\n",
    "ClimateChange_DF[\"1Padded_Word_Index\"] = ClimateChange_DF[\"1Word_Index\"].apply(lambda x: x + [word2index_1[\"PADDING\"]] * (40 - len(x)) if (len(x) <=40) else x[:40])\n",
    "ClimateChange_DF[\"2Padded_Word_Index\"] = ClimateChange_DF[\"2Word_Index\"].apply(lambda x: x + [word2index_2[\"PADDING\"]] * (40 - len(x)) if (len(x) <=40) else x[:40])\n",
    "ClimateChange_DF[\"3Word\"] = ClimateChange_DF[\"CleanedTweets\"].apply(lambda x: [[i] for i in str(x).split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedTweets</th>\n",
       "      <th>1Word</th>\n",
       "      <th>2Word</th>\n",
       "      <th>1Word_Index</th>\n",
       "      <th>2Word_Index</th>\n",
       "      <th>1Padded_Word_Index</th>\n",
       "      <th>2Padded_Word_Index</th>\n",
       "      <th>3Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>News Trends Data Americans are less concerned ...</td>\n",
       "      <td>[News, Trends, Data, Americans, are, less, con...</td>\n",
       "      <td>[news, trends, data, americans, are, less, con...</td>\n",
       "      <td>[26341, 32355, 1041, 4030, 23216, 10517, 25944...</td>\n",
       "      <td>[2165, 325, 9098, 19174, 14213, 11148, 14962, ...</td>\n",
       "      <td>[26341, 32355, 1041, 4030, 23216, 10517, 25944...</td>\n",
       "      <td>[2165, 325, 9098, 19174, 14213, 11148, 14962, ...</td>\n",
       "      <td>[[News], [Trends], [Data], [Americans], [are],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you realize that civil war is the devastati...</td>\n",
       "      <td>[Do, you, realize, that, civil, war, is, the, ...</td>\n",
       "      <td>[do, you, realize, that, civil, war, is, the, ...</td>\n",
       "      <td>[18091, 14666, 20342, 26653, 2796, 32980, 6563...</td>\n",
       "      <td>[11989, 23784, 6400, 8775, 1376, 15117, 8950, ...</td>\n",
       "      <td>[18091, 14666, 20342, 26653, 2796, 32980, 6563...</td>\n",
       "      <td>[11989, 23784, 6400, 8775, 1376, 15117, 8950, ...</td>\n",
       "      <td>[[Do], [you], [realize], [that], [civil], [war...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Having anxiety over the weather something they...</td>\n",
       "      <td>[Having, anxiety, over, the, weather, somethin...</td>\n",
       "      <td>[having, anxiety, over, the, weather, somethin...</td>\n",
       "      <td>[214, 19769, 29935, 8235, 21182, 2958, 35049, ...</td>\n",
       "      <td>[5249, 16605, 15306, 31082, 10820, 26137, 2720...</td>\n",
       "      <td>[214, 19769, 29935, 8235, 21182, 2958, 35049, ...</td>\n",
       "      <td>[5249, 16605, 15306, 31082, 10820, 26137, 2720...</td>\n",
       "      <td>[[Having], [anxiety], [over], [the], [weather]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the last few years I've noticed that studen...</td>\n",
       "      <td>[In, the, last, few, years, I've, noticed, tha...</td>\n",
       "      <td>[in, the, last, few, years, i've, noticed, tha...</td>\n",
       "      <td>[15224, 8235, 8856, 29571, 31255, 0, 12021, 26...</td>\n",
       "      <td>[18193, 31082, 27602, 3214, 21234, 0, 13170, 8...</td>\n",
       "      <td>[15224, 8235, 8856, 29571, 31255, 0, 12021, 26...</td>\n",
       "      <td>[18193, 31082, 27602, 3214, 21234, 0, 13170, 8...</td>\n",
       "      <td>[[In], [the], [last], [few], [years], [I've], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIV...</td>\n",
       "      <td>[FULL, INTERVIEW, BTS, ARMY, BTSonGMA, NEWS, E...</td>\n",
       "      <td>[full, interview, bts, army, btsongma, news, e...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 30322, 21483, 16752, 149...</td>\n",
       "      <td>[2986, 12730, 0, 24604, 0, 2165, 2281, 29986, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 30322, 21483, 16752, 149...</td>\n",
       "      <td>[2986, 12730, 0, 24604, 0, 2165, 2281, 29986, ...</td>\n",
       "      <td>[[FULL], [INTERVIEW], [BTS], [ARMY], [BTSonGMA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       CleanedTweets  \\\n",
       "0  News Trends Data Americans are less concerned ...   \n",
       "1  Do you realize that civil war is the devastati...   \n",
       "2  Having anxiety over the weather something they...   \n",
       "3  In the last few years I've noticed that studen...   \n",
       "4  FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIV...   \n",
       "\n",
       "                                               1Word  \\\n",
       "0  [News, Trends, Data, Americans, are, less, con...   \n",
       "1  [Do, you, realize, that, civil, war, is, the, ...   \n",
       "2  [Having, anxiety, over, the, weather, somethin...   \n",
       "3  [In, the, last, few, years, I've, noticed, tha...   \n",
       "4  [FULL, INTERVIEW, BTS, ARMY, BTSonGMA, NEWS, E...   \n",
       "\n",
       "                                               2Word  \\\n",
       "0  [news, trends, data, americans, are, less, con...   \n",
       "1  [do, you, realize, that, civil, war, is, the, ...   \n",
       "2  [having, anxiety, over, the, weather, somethin...   \n",
       "3  [in, the, last, few, years, i've, noticed, tha...   \n",
       "4  [full, interview, bts, army, btsongma, news, e...   \n",
       "\n",
       "                                         1Word_Index  \\\n",
       "0  [26341, 32355, 1041, 4030, 23216, 10517, 25944...   \n",
       "1  [18091, 14666, 20342, 26653, 2796, 32980, 6563...   \n",
       "2  [214, 19769, 29935, 8235, 21182, 2958, 35049, ...   \n",
       "3  [15224, 8235, 8856, 29571, 31255, 0, 12021, 26...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 30322, 21483, 16752, 149...   \n",
       "\n",
       "                                         2Word_Index  \\\n",
       "0  [2165, 325, 9098, 19174, 14213, 11148, 14962, ...   \n",
       "1  [11989, 23784, 6400, 8775, 1376, 15117, 8950, ...   \n",
       "2  [5249, 16605, 15306, 31082, 10820, 26137, 2720...   \n",
       "3  [18193, 31082, 27602, 3214, 21234, 0, 13170, 8...   \n",
       "4  [2986, 12730, 0, 24604, 0, 2165, 2281, 29986, ...   \n",
       "\n",
       "                                  1Padded_Word_Index  \\\n",
       "0  [26341, 32355, 1041, 4030, 23216, 10517, 25944...   \n",
       "1  [18091, 14666, 20342, 26653, 2796, 32980, 6563...   \n",
       "2  [214, 19769, 29935, 8235, 21182, 2958, 35049, ...   \n",
       "3  [15224, 8235, 8856, 29571, 31255, 0, 12021, 26...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 30322, 21483, 16752, 149...   \n",
       "\n",
       "                                  2Padded_Word_Index  \\\n",
       "0  [2165, 325, 9098, 19174, 14213, 11148, 14962, ...   \n",
       "1  [11989, 23784, 6400, 8775, 1376, 15117, 8950, ...   \n",
       "2  [5249, 16605, 15306, 31082, 10820, 26137, 2720...   \n",
       "3  [18193, 31082, 27602, 3214, 21234, 0, 13170, 8...   \n",
       "4  [2986, 12730, 0, 24604, 0, 2165, 2281, 29986, ...   \n",
       "\n",
       "                                               3Word  \n",
       "0  [[News], [Trends], [Data], [Americans], [are],...  \n",
       "1  [[Do], [you], [realize], [that], [civil], [war...  \n",
       "2  [[Having], [anxiety], [over], [the], [weather]...  \n",
       "3  [[In], [the], [last], [few], [years], [I've], ...  \n",
       "4  [[FULL], [INTERVIEW], [BTS], [ARMY], [BTSonGMA...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClimateChange_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an input list for Glove model\n",
    "model_input = ClimateChange_DF[\"3Word\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Characters\n",
    "predicting_sentence = characterSplit(model_input)\n",
    "#Preprocessing data by adding dummy tags           \n",
    "predicting_sentence = addDummy(predicting_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating lookup dictionaries for tags and words\n",
    "index2Tag_1 = {value: key for key, value in tag2index_1.items()}\n",
    "index2Tag_2 = {value: key for key, value in tag2index_2.items()}\n",
    "word2Idx_Glove = {value: int(key) for key, value in idx2Word_Glove.items()}\n",
    "word2Idx_nonGlove = {value: int(key) for key, value in idx2Word_nonGlove.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating model inputs\n",
    "model_1_input = ClimateChange_DF[\"1Padded_Word_Index\"]\n",
    "model_2_input = ClimateChange_DF[\"2Padded_Word_Index\"]\n",
    "model_3_input = padding(createMatrices(predicting_sentence, word2Idx_Glove, case2Idx, char2Idx), 52)\n",
    "model_4_input = padding(createMatrices(predicting_sentence, word2Idx_nonGlove, case2Idx, char2Idx), 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1685\n",
      "ACTUAL_WORD         BiLSTM         BiLSTM_SC      BiLSTM_CONN_GLOVE   BiLSTM_CONN_NON_GLOVE\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FULL                B-org           O               O                   O\n",
      "INTERVIEW           I-org           O               O                   O\n",
      "BTS                 I-per           B-org           O                   O\n",
      "ARMY                I-per           I-org           I-org               O\n",
      "BTSonGMA            I-per           I-org           I-org               O\n",
      "NEWS                I-per           O               I-org               O\n",
      "EXCLUSIVE           I-per           O               O                   O\n",
      "sits                O               O               O                   O\n",
      "down                O               O               O                   O\n",
      "with                O               O               O                   O\n",
      "pop                 O               O               O                   O\n",
      "superstars          O               O               O                   O\n",
      "and                 O               O               O                   O\n",
      "South               O               O               O                   O\n",
      "Korean              B-gpe           B-gpe           B-gpe               B-gpe\n",
      "Pres                O               O               O                   I-per\n",
      "Moon                B-tim           O               B-per               I-per\n",
      "Jaein               O               O               I-geo               I-per\n",
      "as                  O               O               O                   O\n",
      "they                O               O               O                   O\n",
      "speak               O               O               O                   O\n",
      "on                  O               O               O                   O\n",
      "tackling            O               O               O                   O\n",
      "tough               O               O               O                   O\n",
      "issues              O               O               O                   O\n",
      "from                O               O               O                   O\n",
      "COVID               O               O               B-geo               B-org\n",
      "to                  O               O               O                   O\n",
      "climate             O               O               O                   O\n",
      "change              O               O               O                   O\n",
      "BTS                 B-org           B-org           B-org               O\n",
      "ARMY                I-org           I-org           I-org               O\n",
      "BTSonGMA            I-org           O               I-org               O\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">FULL INTERVIEW BTS ARMY BTSonGMA NEWS EXCLUSIVE sits down with pop superstars and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South Korean\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " Pres Moon Jaein as they speak on tackling tough issues from COVID to climate change BTS ARMY BTSonGMA </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting NER using all 4 models and displaying the words with their tags\n",
    "\n",
    "index = np.random.randint(0, 10000)\n",
    "print(index)\n",
    "#Model Prediction\n",
    "model1_pred, model2_pred , model3_pred, model4_pred = predictTags(index, \n",
    "                                                                  BiLSTM_Final_model, model_1_input,\n",
    "                                                                  BiLSTM_Final_model_strict_clean, model_2_input,\n",
    "                                                                  BiLSTM_CNN_model_glove, model_3_input,\n",
    "                                                                  BiLSTM_CNN_model_non_glove, model_4_input)\n",
    "#Predicted Entity display                                                                 \n",
    "predictedDisplay(ClimateChange_DF, index, model1_pred, index2Tag_1, model2_pred,index2Tag_2, model3_pred,idx2Label_Glove,\n",
    "                 model4_pred, idx2Label_nonGlove)\n",
    "\n",
    "#To validate using an external NLP library and printing entities\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = nlp(ClimateChange_DF.CleanedTweets[index])\n",
    "displacy.render(text, style = 'ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClimateChange_DF.CleanedTweets[index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
